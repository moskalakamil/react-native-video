"use strict";(self.webpackChunk_react_native_video_docs=self.webpackChunk_react_native_video_docs||[]).push([["6144"],{49578:function(e,n,s){s.r(n),s.d(n,{frontMatter:()=>a,toc:()=>l,default:()=>h,metadata:()=>r,assets:()=>c,contentTitle:()=>o});var r=JSON.parse('{"id":"players/usage/frame-processors","title":"Frame Processors","description":"Process video frames in realtime using JavaScript or native plugins.","source":"@site/docs/players/usage/frame-processors.md","sourceDirName":"players/usage","slug":"/players/usage/frame-processors","permalink":"/react-native-video/docs/v7/players/usage/frame-processors","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"docsSidebar","previous":{"title":"Status","permalink":"/react-native-video/docs/v7/players/usage/status"},"next":{"title":"Notification Controls","permalink":"/react-native-video/docs/v7/players/usage/notification-controls"}}'),t=s(74848),i=s(56151);let a={},o="Frame Processors",c={},l=[{value:"What are Frame Processors?",id:"what-are-frame-processors",level:2},{value:"Use Cases",id:"use-cases",level:2},{value:"Real-World Examples",id:"real-world-examples",level:2},{value:"Ambient Mode (Dynamic Colors)",id:"ambient-mode-dynamic-colors",level:3},{value:"Visual Product Search (E-commerce)",id:"visual-product-search-e-commerce",level:3},{value:"Installation",id:"installation",level:2},{value:"The Frame Object",id:"the-frame-object",level:2},{value:"Frame Properties",id:"frame-properties",level:3},{value:"Accessing Pixel Data",id:"accessing-pixel-data",level:3},{value:"Native Plugins",id:"native-plugins",level:2},{value:"Using Community Plugins",id:"using-community-plugins",level:3},{value:"Creating Custom Plugins",id:"creating-custom-plugins",level:3},{value:"Drawing with Skia",id:"drawing-with-skia",level:2},{value:"Drawing Examples",id:"drawing-examples",level:3},{value:"Performance",id:"performance",level:2},{value:"Timing Constraints",id:"timing-constraints",level:3},{value:"Optimization Tips",id:"optimization-tips",level:3},{value:"Complete Example",id:"complete-example",level:2},{value:"Platform Support",id:"platform-support",level:2},{value:"Disabling Frame Processors",id:"disabling-frame-processors",level:2},{value:"See Also",id:"see-also",level:2}];function d(e){let n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,i.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"frame-processors",children:"Frame Processors"})}),"\n",(0,t.jsx)(n.p,{children:"Process video frames in realtime using JavaScript or native plugins."}),"\n",(0,t.jsx)(n.admonition,{title:"Pro Feature - Coming Soon",type:"tip",children:(0,t.jsx)(n.p,{children:"Frame Processors are a Pro feature currently in development. They enable realtime video analysis and manipulation."})}),"\n",(0,t.jsx)(n.h2,{id:"what-are-frame-processors",children:"What are Frame Processors?"}),"\n",(0,t.jsx)(n.p,{children:"Frame Processors are JavaScript functions called for each frame the player renders. Inside these functions you can:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Analyze frames"})," in realtime using native plugins"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Draw overlays"})," directly onto frames using Skia"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Extract data"})," like colors, objects, or text"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Apply filters"})," and visual effects"]}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-tsx",children:"const frameProcessor = useFrameProcessor((frame) => {\n  'worklet';\n  const objects = detectObjects(frame);\n  console.log(`Detected: ${objects[0]?.name}`);\n}, []);\n\nreturn <VideoView player={player} frameProcessor={frameProcessor} />;\n"})}),"\n",(0,t.jsx)(n.h2,{id:"use-cases",children:"Use Cases"}),"\n",(0,t.jsx)(n.p,{children:"Frame Processors enable powerful video processing capabilities:"}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"Use Case"}),(0,t.jsx)(n.th,{children:"Description"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Ambient Mode"})}),(0,t.jsx)(n.td,{children:"Extract colors for dynamic UI gradients"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Visual Product Search"})}),(0,t.jsx)(n.td,{children:"Detect products/clothing for e-commerce"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Object Detection"})}),(0,t.jsx)(n.td,{children:"Detect and track objects in video"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Face Recognition"})}),(0,t.jsx)(n.td,{children:"Identify faces and expressions"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Text Recognition (OCR)"})}),(0,t.jsx)(n.td,{children:"Extract text from video frames"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Motion Detection"})}),(0,t.jsx)(n.td,{children:"Detect movement or scene changes"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Custom Overlays"})}),(0,t.jsx)(n.td,{children:"Draw graphics, text, or AR elements"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Content Moderation"})}),(0,t.jsx)(n.td,{children:"Detect inappropriate content"})]})]})]}),"\n",(0,t.jsx)(n.h2,{id:"real-world-examples",children:"Real-World Examples"}),"\n",(0,t.jsx)(n.h3,{id:"ambient-mode-dynamic-colors",children:"Ambient Mode (Dynamic Colors)"}),"\n",(0,t.jsx)(n.p,{children:"Extract dominant colors from the video to create ambient lighting effects around the player. This creates an immersive experience where UI elements like borders or backgrounds match the video content."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-tsx",children:"import React, { useState } from 'react';\nimport { View } from 'react-native';\nimport { useVideoPlayer, VideoView, useFrameProcessor, runOnJS } from 'react-native-video';\n\nfunction AmbientVideoPlayer({ source }) {\n  const [ambientColor, setAmbientColor] = useState('#000000');\n\n  const player = useVideoPlayer(source, (_player) => {\n    _player.play();\n  });\n\n  const frameProcessor = useFrameProcessor((frame) => {\n    'worklet';\n    // Extract dominant color from frame edges\n    const color = extractDominantColor(frame, {\n      region: 'edges', // Focus on edges for ambient effect\n      sampleSize: 50,\n    });\n    \n    runOnJS(setAmbientColor)(color);\n  }, []);\n\n  return (\n    <View style={[styles.container, { backgroundColor: ambientColor }]}>\n      <View style={[styles.ambientGlow, { \n        shadowColor: ambientColor,\n        shadowRadius: 50,\n        shadowOpacity: 0.8,\n      }]}>\n        <VideoView \n          player={player} \n          frameProcessor={frameProcessor}\n          style={styles.video} \n        />\n      </View>\n    </View>\n  );\n}\n"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Features:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Real-time color extraction from video frames"}),"\n",(0,t.jsx)(n.li,{children:"Smooth color transitions with interpolation"}),"\n",(0,t.jsx)(n.li,{children:"Region-based sampling (edges, center, full frame)"}),"\n",(0,t.jsx)(n.li,{children:"Perfect for music videos, ambient displays, and immersive UIs"}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"visual-product-search-e-commerce",children:"Visual Product Search (E-commerce)"}),"\n",(0,t.jsx)(n.p,{children:"Detect clothing and products in video content for shoppable experiences. Users can tap on items to find similar products for purchase."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-tsx",children:"import React, { useState } from 'react';\nimport { View, TouchableOpacity, Image } from 'react-native';\nimport { useVideoPlayer, VideoView, useFrameProcessor, runOnJS } from 'react-native-video';\n\nfunction ShoppableVideoPlayer({ source }) {\n  const [detectedProducts, setDetectedProducts] = useState([]);\n  const [isPaused, setIsPaused] = useState(false);\n\n  const player = useVideoPlayer(source, (_player) => {\n    _player.play();\n  });\n\n  const frameProcessor = useFrameProcessor((frame) => {\n    'worklet';\n    // Detect clothing and products in frame\n    const products = detectProducts(frame, {\n      categories: ['clothing', 'accessories', 'shoes'],\n      minConfidence: 0.7,\n    });\n    \n    // Map to screen coordinates\n    const mapped = products.map(p => ({\n      id: p.id,\n      category: p.category,\n      bounds: p.bounds,\n      confidence: p.confidence,\n    }));\n    \n    runOnJS(setDetectedProducts)(mapped);\n  }, []);\n\n  const handleProductTap = async (product) => {\n    player.pause();\n    setIsPaused(true);\n    \n    // Search for similar products\n    const results = await searchSimilarProducts(product);\n    showProductSheet(results);\n  };\n\n  return (\n    <View style={styles.container}>\n      <VideoView \n        player={player} \n        frameProcessor={frameProcessor}\n        style={styles.video} \n      />\n      \n      {/* Product hotspots */}\n      {detectedProducts.map((product) => (\n        <TouchableOpacity\n          key={product.id}\n          style={[styles.hotspot, {\n            left: product.bounds.x,\n            top: product.bounds.y,\n            width: product.bounds.width,\n            height: product.bounds.height,\n          }]}\n          onPress={() => handleProductTap(product)}\n        >\n          <View style={styles.hotspotIndicator} />\n        </TouchableOpacity>\n      ))}\n    </View>\n  );\n}\n"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Features:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Real-time clothing and product detection"}),"\n",(0,t.jsx)(n.li,{children:"Tap-to-shop functionality"}),"\n",(0,t.jsx)(n.li,{children:"Category filtering (clothing, accessories, shoes, etc.)"}),"\n",(0,t.jsx)(n.li,{children:"Integration with product catalogs and search APIs"}),"\n",(0,t.jsx)(n.li,{children:"Perfect for fashion videos, influencer content, and live shopping"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"installation",children:"Installation"}),"\n",(0,t.jsxs)(n.p,{children:["Frame Processors require ",(0,t.jsx)(n.code,{children:"react-native-worklets-core"}),":"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"npm install react-native-worklets-core\n"})}),"\n",(0,t.jsxs)(n.p,{children:["Add the plugin to your ",(0,t.jsx)(n.code,{children:"babel.config.js"}),":"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-js",children:"module.exports = {\n  plugins: [\n    ['react-native-worklets-core/plugin'],\n  ],\n};\n"})}),"\n",(0,t.jsx)(n.h2,{id:"the-frame-object",children:"The Frame Object"}),"\n",(0,t.jsx)(n.p,{children:"A video frame contains pixel data and metadata:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-tsx",children:"const frameProcessor = useFrameProcessor((frame) => {\n  'worklet';\n  console.log(`Frame: ${frame.width}x${frame.height}`);\n  console.log(`Format: ${frame.pixelFormat}`);\n  console.log(`Timestamp: ${frame.timestamp}ms`);\n}, []);\n"})}),"\n",(0,t.jsx)(n.h3,{id:"frame-properties",children:"Frame Properties"}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"Property"}),(0,t.jsx)(n.th,{children:"Type"}),(0,t.jsx)(n.th,{children:"Description"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"width"})}),(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"number"})}),(0,t.jsx)(n.td,{children:"Frame width in pixels"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"height"})}),(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"number"})}),(0,t.jsx)(n.td,{children:"Frame height in pixels"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"pixelFormat"})}),(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"string"})}),(0,t.jsxs)(n.td,{children:["Pixel format (",(0,t.jsx)(n.code,{children:"'rgb'"}),", ",(0,t.jsx)(n.code,{children:"'yuv'"}),", etc.)"]})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"timestamp"})}),(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"number"})}),(0,t.jsx)(n.td,{children:"Frame timestamp in milliseconds"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"bytesPerRow"})}),(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"number"})}),(0,t.jsx)(n.td,{children:"Bytes per row of pixel data"})]})]})]}),"\n",(0,t.jsx)(n.h3,{id:"accessing-pixel-data",children:"Accessing Pixel Data"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-tsx",children:"const frameProcessor = useFrameProcessor((frame) => {\n  'worklet';\n  if (frame.pixelFormat === 'rgb') {\n    const buffer = frame.toArrayBuffer();\n    const data = new Uint8Array(buffer);\n    // First pixel RGB values\n    console.log(`RGB(${data[0]}, ${data[1]}, ${data[2]})`);\n  }\n}, []);\n"})}),"\n",(0,t.jsx)(n.admonition,{type:"note",children:(0,t.jsx)(n.p,{children:"At 1080p, a raw frame is ~6MB. At 60 FPS, ~360MB/second flows through your processor. Use native plugins for heavy processing."})}),"\n",(0,t.jsx)(n.h2,{id:"native-plugins",children:"Native Plugins"}),"\n",(0,t.jsx)(n.p,{children:"For performance-critical tasks, use native Frame Processor Plugins written in Swift/Kotlin/C++."}),"\n",(0,t.jsx)(n.h3,{id:"using-community-plugins",children:"Using Community Plugins"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"npm install vision-camera-image-labeler\ncd ios && pod install\n"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-tsx",children:"import { useImageLabeler } from 'vision-camera-image-labeler';\n\nfunction VideoAnalyzer() {\n  const { labelImage } = useImageLabeler();\n\n  const frameProcessor = useFrameProcessor((frame) => {\n    'worklet';\n    const labels = labelImage(frame);\n    console.log(`Detected: ${labels[0]?.name}`);\n  }, [labelImage]);\n\n  return <VideoView player={player} frameProcessor={frameProcessor} />;\n}\n"})}),"\n",(0,t.jsx)(n.h3,{id:"creating-custom-plugins",children:"Creating Custom Plugins"}),"\n",(0,t.jsx)(n.p,{children:"Create native plugins for optimal performance:"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"iOS (Swift):"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-swift",children:"@objc(ObjectDetector)\npublic class ObjectDetectorPlugin: FrameProcessorPlugin {\n  public override func callback(_ frame: Frame, withArguments args: [AnyHashable: Any]) -> Any {\n    let imageBuffer = frame.buffer\n    let objects = MLKit.detectObjects(imageBuffer)\n    return objects.map { $0.toJson() }\n  }\n}\n"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Android (Kotlin):"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-kotlin",children:"class ObjectDetectorPlugin : FrameProcessorPlugin() {\n  override fun callback(frame: Frame, params: Map<String, Any>): Any {\n    val image = frame.image\n    val objects = MLKit.detectObjects(image)\n    return objects.map { it.toJson() }\n  }\n}\n"})}),"\n",(0,t.jsx)(n.h2,{id:"drawing-with-skia",children:"Drawing with Skia"}),"\n",(0,t.jsx)(n.p,{children:"Draw directly onto frames using Skia:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-tsx",children:"import { Skia } from '@shopify/react-native-skia';\n\nconst frameProcessor = useFrameProcessor((frame) => {\n  'worklet';\n  \n  // Detect faces\n  const faces = detectFaces(frame);\n  \n  // Draw rectangles around faces\n  const canvas = frame.getSkiaCanvas();\n  const paint = Skia.Paint();\n  paint.setColor(Skia.Color('cyan'));\n  paint.setStyle('stroke');\n  paint.setStrokeWidth(3);\n  \n  for (const face of faces) {\n    canvas.drawRect(face.bounds, paint);\n  }\n}, []);\n"})}),"\n",(0,t.jsx)(n.h3,{id:"drawing-examples",children:"Drawing Examples"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Text overlay:"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-tsx",children:"const frameProcessor = useFrameProcessor((frame) => {\n  'worklet';\n  const canvas = frame.getSkiaCanvas();\n  const font = Skia.Font(null, 24);\n  const paint = Skia.Paint();\n  paint.setColor(Skia.Color('white'));\n  \n  canvas.drawText('LIVE', 20, 40, font, paint);\n}, []);\n"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Blur region:"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-tsx",children:"const frameProcessor = useFrameProcessor((frame) => {\n  'worklet';\n  const faces = detectFaces(frame);\n  \n  for (const face of faces) {\n    frame.applyBlur(face.bounds, 20); // 20px blur radius\n  }\n}, []);\n"})}),"\n",(0,t.jsx)(n.h2,{id:"performance",children:"Performance"}),"\n",(0,t.jsx)(n.p,{children:"Frame Processors run synchronously in the render pipeline."}),"\n",(0,t.jsx)(n.h3,{id:"timing-constraints",children:"Timing Constraints"}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"FPS"}),(0,t.jsx)(n.th,{children:"Time per Frame"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"24"}),(0,t.jsx)(n.td,{children:"41ms"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"30"}),(0,t.jsx)(n.td,{children:"33ms"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"60"}),(0,t.jsx)(n.td,{children:"16ms"})]})]})]}),"\n",(0,t.jsx)(n.h3,{id:"optimization-tips",children:"Optimization Tips"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Lower resolution"})," - Process at lower resolution when possible:"]}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-tsx",children:"const player = useVideoPlayer({\n  uri: source,\n  frameProcessorResolution: { width: 640, height: 360 },\n});\n"})}),"\n",(0,t.jsxs)(n.ol,{start:"2",children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Skip frames"})," - Process every Nth frame:"]}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-tsx",children:"let frameCount = 0;\n\nconst frameProcessor = useFrameProcessor((frame) => {\n  'worklet';\n  frameCount++;\n  if (frameCount % 3 !== 0) return; // Process every 3rd frame\n  \n  const result = heavyProcessing(frame);\n}, []);\n"})}),"\n",(0,t.jsxs)(n.ol,{start:"3",children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Use native plugins"})," - Offload heavy work to native code"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Async processing"})," - Queue results for async handling:"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-tsx",children:"const frameProcessor = useFrameProcessor((frame) => {\n  'worklet';\n  const result = detectObjects(frame);\n  \n  // Send to JS thread asynchronously\n  runOnJS(handleDetection)(result);\n}, []);\n"})}),"\n",(0,t.jsx)(n.h2,{id:"complete-example",children:"Complete Example"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-tsx",children:"import React, { useState } from 'react';\nimport { View, Text } from 'react-native';\nimport { useVideoPlayer, VideoView, useFrameProcessor, runOnJS } from 'react-native-video';\n\nfunction ObjectDetectionPlayer({ source }) {\n  const [detectedObjects, setDetectedObjects] = useState<string[]>([]);\n\n  const player = useVideoPlayer(source, (_player) => {\n    _player.play();\n  });\n\n  const frameProcessor = useFrameProcessor((frame) => {\n    'worklet';\n    \n    // Detect objects using native plugin\n    const objects = detectObjects(frame, {\n      maxResults: 5,\n      minConfidence: 0.7,\n    });\n    \n    // Extract names\n    const names = objects.map(obj => obj.name);\n    \n    // Update React state (async)\n    runOnJS(setDetectedObjects)(names);\n  }, []);\n\n  return (\n    <View>\n      <VideoView \n        player={player} \n        frameProcessor={frameProcessor}\n        style={{ width: '100%', height: 300 }} \n      />\n      \n      <View style={styles.overlay}>\n        <Text style={styles.title}>Detected Objects:</Text>\n        {detectedObjects.map((obj, i) => (\n          <Text key={i} style={styles.object}>\u2022 {obj}</Text>\n        ))}\n      </View>\n    </View>\n  );\n}\n"})}),"\n",(0,t.jsx)(n.h2,{id:"platform-support",children:"Platform Support"}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"Feature"}),(0,t.jsx)(n.th,{children:"iOS"}),(0,t.jsx)(n.th,{children:"Android"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Frame access"}),(0,t.jsx)(n.td,{children:"\u2705"}),(0,t.jsx)(n.td,{children:"\u2705"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Native plugins"}),(0,t.jsx)(n.td,{children:"\u2705"}),(0,t.jsx)(n.td,{children:"\u2705"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Skia drawing"}),(0,t.jsx)(n.td,{children:"\u2705"}),(0,t.jsx)(n.td,{children:"\u2705"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"GPU acceleration"}),(0,t.jsx)(n.td,{children:"\u2705"}),(0,t.jsx)(n.td,{children:"\u2705"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Custom resolution"}),(0,t.jsx)(n.td,{children:"\u2705"}),(0,t.jsx)(n.td,{children:"\u2705"})]})]})]}),"\n",(0,t.jsx)(n.h2,{id:"disabling-frame-processors",children:"Disabling Frame Processors"}),"\n",(0,t.jsx)(n.p,{children:"If not using Frame Processors, disable them to reduce bundle size:"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsxs)(n.strong,{children:["Android (",(0,t.jsx)(n.code,{children:"gradle.properties"}),"):"]})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-properties",children:"ReactNativeVideo_enableFrameProcessors=false\n"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsxs)(n.strong,{children:["iOS (",(0,t.jsx)(n.code,{children:"Podfile"}),"):"]})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-ruby",children:"$RNVideoEnableFrameProcessors = false\n"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsxs)(n.strong,{children:["Expo (",(0,t.jsx)(n.code,{children:"app.json"}),"):"]})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-json",children:'{\n  "plugins": [\n    ["react-native-video", {\n      "enableFrameProcessors": false\n    }]\n  ]\n}\n'})}),"\n",(0,t.jsx)(n.h2,{id:"see-also",children:"See Also"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"https://react-native-vision-camera.com/docs/guides/frame-processors",children:"VisionCamera Frame Processors"})," - Similar API for camera frames"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"/react-native-video/docs/v7/players/usage/playback",children:"Playback"})," - Video playback controls"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"/react-native-video/docs/v7/players/events/useEvent",children:"Events"})," - Event handling"]}),"\n"]})]})}function h(e={}){let{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},56151:function(e,n,s){s.d(n,{R:()=>a,x:()=>o});var r=s(96540);let t={},i=r.createContext(t);function a(e){let n=r.useContext(i);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:a(e.components),r.createElement(i.Provider,{value:n},e.children)}}}]);